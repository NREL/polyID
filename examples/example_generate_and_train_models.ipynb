{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyid.preprocessors import PolymerPreprocessor\n",
    "from polyid import MultiModel, Parameters\n",
    "from polyid.models import global100\n",
    "\n",
    "from nfp.preprocessing.features import atom_features_v1, bond_features_v1\n",
    "from model_utils import bond_featurizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic data for Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "dftrain = pd.read_csv('../data/example_polymer_smiles_train.csv',index_col=0)\n",
    "dftrain['fake_Tg'] = np.random.uniform(low=-100, \n",
    "                            high=250, \n",
    "                            size=(dftrain.shape[0],))\n",
    "dftrain['fake_Tm'] = dftrain.fake_Tg*0.62+100\n",
    "dftrain.to_csv('../data/example_polymer_data_train.csv')\n",
    "\n",
    "# test data\n",
    "dftest = pd.read_csv('../data/example_polymer_smiles_test.csv',index_col=0)\n",
    "dftest['fake_Tg'] = np.random.uniform(low=-100, \n",
    "                            high=250, \n",
    "                            size=(dftest.shape[0],))\n",
    "dftest['fake_Tm'] = dftest.fake_Tg*0.62+100\n",
    "dftest.to_csv('../data/example_polymer_data_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation and Training of Data\n",
    "This notebook highlights an example workflow to use polyID to make a machine learning model and make predictions for Tg and Tm of polymers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Training using Only Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kfolds': 3, 'prediction_columns': ['fake_Tg', 'fake_Tm'], 'atom_features': 32, 'mol_features': 8, 'num_messages': 2, 'batch_size': 64, 'epochs': 5, 'learning_rate': 0.0005, 'dropout': 0.05, 'decay': 1e-05, 'bond_features': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 08:53:27.663475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.functional.Functional object at 0x7fa718105690>>\n",
      "Epoch 1/5\n",
      "    300/Unknown - 13s 15ms/step - loss: 78.3854\n",
      "Epoch 1: val_loss improved from inf to 89.32783, saving model to save_example/model_0/model_0.h5\n",
      "306/306 [==============================] - 18s 31ms/step - loss: 78.3000 - val_loss: 89.3278\n",
      "Epoch 2/5\n",
      "301/306 [============================>.] - ETA: 0s - loss: 73.9907\n",
      "Epoch 2: val_loss improved from 89.32783 to 76.84061, saving model to save_example/model_0/model_0.h5\n",
      "306/306 [==============================] - 4s 12ms/step - loss: 74.0248 - val_loss: 76.8406\n",
      "Epoch 3/5\n",
      "302/306 [============================>.] - ETA: 0s - loss: 71.2285\n",
      "Epoch 3: val_loss did not improve from 76.84061\n",
      "306/306 [==============================] - 3s 10ms/step - loss: 71.4634 - val_loss: 82.4324\n",
      "Epoch 4/5\n",
      "301/306 [============================>.] - ETA: 0s - loss: 72.4638\n",
      "Epoch 4: val_loss did not improve from 76.84061\n",
      "306/306 [==============================] - 3s 9ms/step - loss: 71.9891 - val_loss: 76.9534\n",
      "Epoch 5/5\n",
      "301/306 [============================>.] - ETA: 0s - loss: 69.4644\n",
      "Epoch 5: val_loss improved from 76.84061 to 74.15756, saving model to save_example/model_0/model_0.h5\n",
      "306/306 [==============================] - 4s 12ms/step - loss: 69.9915 - val_loss: 74.1576\n",
      "156/156 [==============================] - 4s 22ms/step\n",
      "<bound method Model.summary of <keras.engine.functional.Functional object at 0x7fa719a0f650>>\n",
      "Epoch 1/5\n",
      "    313/Unknown - 12s 13ms/step - loss: 85.1551\n",
      "Epoch 1: val_loss improved from inf to 68.01556, saving model to save_example/model_1/model_1.h5\n",
      "314/314 [==============================] - 16s 25ms/step - loss: 85.0103 - val_loss: 68.0156\n",
      "Epoch 2/5\n",
      "313/314 [============================>.] - ETA: 0s - loss: 76.0878\n",
      "Epoch 2: val_loss did not improve from 68.01556\n",
      "314/314 [==============================] - 4s 13ms/step - loss: 76.2481 - val_loss: 69.0471\n",
      "Epoch 3/5\n",
      "311/314 [============================>.] - ETA: 0s - loss: 74.5679\n",
      "Epoch 3: val_loss improved from 68.01556 to 67.97594, saving model to save_example/model_1/model_1.h5\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 74.9988 - val_loss: 67.9759\n",
      "Epoch 4/5\n",
      "314/314 [==============================] - ETA: 0s - loss: 74.8830\n",
      "Epoch 4: val_loss did not improve from 67.97594\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 74.8830 - val_loss: 69.3567\n",
      "Epoch 5/5\n",
      "314/314 [==============================] - ETA: 0s - loss: 75.2464\n",
      "Epoch 5: val_loss did not improve from 67.97594\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 75.2464 - val_loss: 74.7702\n",
      "148/148 [==============================] - 4s 18ms/step\n",
      "<bound method Model.summary of <keras.engine.functional.Functional object at 0x7fa721006e90>>\n",
      "Epoch 1/5\n",
      "    300/Unknown - 13s 13ms/step - loss: 79.1207\n",
      "Epoch 1: val_loss improved from inf to 73.43007, saving model to save_example/model_2/model_2.h5\n",
      "304/304 [==============================] - 16s 25ms/step - loss: 79.1903 - val_loss: 73.4301\n",
      "Epoch 2/5\n",
      "303/304 [============================>.] - ETA: 0s - loss: 70.9114\n",
      "Epoch 2: val_loss did not improve from 73.43007\n",
      "304/304 [==============================] - 4s 12ms/step - loss: 71.1486 - val_loss: 80.5340\n",
      "Epoch 3/5\n",
      "302/304 [============================>.] - ETA: 0s - loss: 71.7579\n",
      "Epoch 3: val_loss did not improve from 73.43007\n",
      "304/304 [==============================] - 3s 8ms/step - loss: 71.4217 - val_loss: 81.3420\n",
      "Epoch 4/5\n",
      "299/304 [============================>.] - ETA: 0s - loss: 73.2274\n",
      "Epoch 4: val_loss did not improve from 73.43007\n",
      "304/304 [==============================] - 3s 9ms/step - loss: 73.0261 - val_loss: 74.9532\n",
      "Epoch 5/5\n",
      "299/304 [============================>.] - ETA: 0s - loss: 70.0903\n",
      "Epoch 5: val_loss did not improve from 73.43007\n",
      "304/304 [==============================] - 3s 9ms/step - loss: 70.0616 - val_loss: 81.1147\n",
      "158/158 [==============================] - 4s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate model parameters\n",
    "# Paremeters has default values that can be changed\n",
    "params = Parameters()\n",
    "params.prediction_columns = [\"fake_Tg\", \"fake_Tm\"]\n",
    "print(params.to_dict())\n",
    "\n",
    "# Create the MultiModel class that manages multiple SingleModels\n",
    "mm = MultiModel()\n",
    "\n",
    "# First load data in, specifying prediction columns as well\n",
    "mm.load_dataset('../data/example_polymer_data_train.csv', prediction_columns=params.prediction_columns)\n",
    "\n",
    "# Split the data up into kfolds and generate the model classes\n",
    "mm.split_data(kfolds=params.kfolds)\n",
    "\n",
    "# # Scale the data. This scales using the entire data set and then scales each individual model with that scaler\n",
    "mm.generate_data_scaler()\n",
    "\n",
    "# # Generate the preprocessors for each model\n",
    "# Here we use a preprocessor that uses just smiles\n",
    "mm.generate_preprocessors(preprocessor=PolymerPreprocessor, atom_features=atom_features_v1, bond_features=bond_features_v1)\n",
    "\n",
    "# # Train the models\n",
    "mm.train_models(modelbuilder=global100, model_params=params.to_dict(), save_folder=\"save_example\", save_training=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('polyID')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b479e74d0a1a0222305f58eaed2f757cf21fa5e4690689fbf117b068e599aac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
