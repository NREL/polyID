{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a message passing neural network using a 10 fold cross validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyid.preprocessors import PolymerPreprocessor\n",
    "from polyid import MultiModel, Parameters\n",
    "from polyid.models import global100\n",
    "\n",
    "from nfp.preprocessing.features import atom_features_v1, bond_features_v1\n",
    "from model_utils import bond_featurizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model parameters\n",
    "# Paremeters has default values that can be changed\n",
    "# For optimized hyperparameters see forthcoming publication.\n",
    "params = Parameters()\n",
    "params.prediction_columns = ['Glass_Transition',\n",
    "                             'Melt_Temp',\n",
    "                             'Density',\n",
    "                             'log10_Permeability_CO2', \n",
    "                             'log10_Permeability_N2', \n",
    "                             'log10_Permeability_O2', \n",
    "                             'YoungMod']\n",
    "params.epochs = 500 # recommended 500 - 1000\n",
    "params.kfolds = 10 # recommended 10\n",
    "print(pd.DataFrame(pd.Series(params.to_dict()),columns=['parameter']),'\\n')\n",
    "\n",
    "# Create the MultiModel class that manages multiple SingleModels\n",
    "mm = MultiModel()\n",
    "\n",
    "# Load data in and specify prediction columns\n",
    "mm.load_dataset('../data/dftrain.csv', prediction_columns=params.prediction_columns)\n",
    "\n",
    "# Split the data up into kfolds and generate the model classes\n",
    "mm.split_data(kfolds=params.kfolds)\n",
    "\n",
    "# Scale the data. This scales using the entire data set and then scales each individual model with that scaler\n",
    "mm.generate_data_scaler()\n",
    "\n",
    "# Generate the preprocessors for each model\n",
    "# Here we use a preprocessor that uses just smiles\n",
    "mm.generate_preprocessors(preprocessor=PolymerPreprocessor, atom_features=atom_features_v1, bond_features=bond_features_v1)\n",
    "\n",
    "# Train the models\n",
    "mm.train_models(modelbuilder=global100, model_params=params.to_dict(), save_folder=\"save_examples\", save_training=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('polyID')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "267d97aa68998e1388018e331430e49a3b8c6b7c8ff96a5c0d89ba2bb72ea730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
