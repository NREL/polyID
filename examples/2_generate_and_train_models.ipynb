{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a message passing neural network using a 10 fold cross validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 14:09:33.013211: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-23 14:09:33.378772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64::/home/wilsoa6/miniconda3/envs/stonks/lib/\n",
      "2023-09-23 14:09:33.378840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64::/home/wilsoa6/miniconda3/envs/stonks/lib/\n",
      "2023-09-23 14:09:33.378844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from polyid.preprocessors import PolymerPreprocessor\n",
    "from polyid import MultiModel, Parameters\n",
    "from polyid.models import global100\n",
    "\n",
    "from nfp.preprocessing.features import atom_features_v1, bond_features_v1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model parameters\n",
    "params = Parameters()\n",
    "\n",
    "# Optimized hyperparameters from publication.\n",
    "params.batch_size = 1\n",
    "params.learning_rate = 1E-4\n",
    "params.decay = 1E-5\n",
    "params.atom_features = 128\n",
    "params.bond_features = 128\n",
    "params.num_messages = 12 \n",
    "\n",
    "# Parameters for training example\n",
    "params.prediction_columns = ['Glass_Transition',\n",
    "                            'Melt_Temp',\n",
    "                            'Density',\n",
    "                            'log10_Permeability_CO2', \n",
    "                            'log10_Permeability_N2', \n",
    "                            'log10_Permeability_O2', \n",
    "                            'YoungMod']\n",
    "params.epochs = 500 # recommended 500 - 1000\n",
    "params.kfolds = 10\n",
    "\n",
    "print(pd.DataFrame(pd.Series(params.to_dict()),columns=['parameter']),'\\n')\n",
    "\n",
    "# Create the MultiModel class that manages multiple SingleModels\n",
    "mm = MultiModel()\n",
    "\n",
    "# Load data in and specify prediction columns\n",
    "mm.load_dataset('../data/dftrain.csv', prediction_columns=params.prediction_columns)\n",
    "\n",
    "# Split the data up into kfolds and generate the model classes\n",
    "mm.split_data(kfolds=params.kfolds)\n",
    "\n",
    "# Scale the data. This scales using the entire data set and then scales each individual model with that scaler\n",
    "mm.generate_data_scaler()\n",
    "\n",
    "# Generate the preprocessors for each model\n",
    "# Here we use a preprocessor that uses just smiles\n",
    "mm.generate_preprocessors(preprocessor=PolymerPreprocessor, atom_features=atom_features_v1, bond_features=bond_features_v1,batch_size=params.batch_size)\n",
    "\n",
    "# Train the models\n",
    "mm.train_models(modelbuilder=global100, model_params=params.to_dict(), save_folder=\"save_examples\", save_training=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('polyID')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "267d97aa68998e1388018e331430e49a3b8c6b7c8ff96a5c0d89ba2bb72ea730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
